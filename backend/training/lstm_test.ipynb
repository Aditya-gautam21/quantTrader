{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d24c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LSTM FEATURE ABLATION - Testing Redundancy Hypothesis\n",
      "======================================================================\n",
      "\n",
      "Feature Sets to Test:\n",
      "  returns_only        : 1 features - ['RET_1']\n",
      "  returns_momentum    : 3 features - ['RET_1', 'RSI_14', 'MACD_HIST']\n",
      "  momentum_original   : 5 features - ['RSI_14', 'MACD_HIST', 'RET_1', 'RET_5', 'RET_15']\n",
      "  momentum_clean      : 3 features - ['RSI_14', 'MACD_HIST', 'RET_1']\n",
      "  momentum_position   : 5 features - ['RSI_14', 'MACD_HIST', 'RET_1', 'BB_POSITION', 'PRICE_EMA21_DIST']\n",
      "  minimal             : 2 features - ['RET_1', 'RSI_14']\n",
      "  comprehensive       : 8 features - ['RSI_14', 'MACD_HIST', 'RET_1', 'BB_POSITION', 'PRICE_EMA21_DIST', 'ATR', 'VOL', 'VWAP_DIST']\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bfce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Testing: returns_only (1 features)\n",
      "Features: ['RET_1']\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m X_data = \u001b[43mclean_data\u001b[49m[feature_list].values\n\u001b[32m     32\u001b[39m y_data = y_regression\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Split (chronological)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'clean_data' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMPREHENSIVE LSTM FEATURE ABLATION\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuration\n",
    "SEQUENCE_LENGTH = 20\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Results storage\n",
    "lstm_results = {}\n",
    "\n",
    "for set_name, feature_list in lstm_feature_sets.items():\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing: {set_name} ({len(feature_list)} features)\")\n",
    "    print(f\"Features: {feature_list}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Extract features\n",
    "    X_data = clean_data[feature_list].values\n",
    "    y_data = y_regression\n",
    "    \n",
    "    # Split (chronological)\n",
    "    n = len(X_data)\n",
    "    test_start = int(n * 0.8)\n",
    "    val_start = int(test_start * 0.9)\n",
    "    \n",
    "    X_train_raw = X_data[:val_start]\n",
    "    y_train_raw = y_data[:val_start]\n",
    "    X_val_raw = X_data[val_start:test_start]\n",
    "    y_val_raw = y_data[val_start:test_start]\n",
    "    X_test_raw = X_data[test_start:]\n",
    "    y_test_raw = y_data[test_start:]\n",
    "    \n",
    "    # Create sequence datasets\n",
    "    train_dataset = SequenceDataset(X_train_raw, y_train_raw, SEQUENCE_LENGTH)\n",
    "    val_dataset = SequenceDataset(X_val_raw, y_val_raw, SEQUENCE_LENGTH)\n",
    "    test_dataset = SequenceDataset(X_test_raw, y_test_raw, SEQUENCE_LENGTH)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    input_size = len(feature_list)\n",
    "    model = LSTMPredictor(input_size, HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Training\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                preds = model(x_batch)\n",
    "                val_loss += criterion(preds, y_batch).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "    \n",
    "    # Test\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            preds = model(x_batch).cpu().numpy().flatten()\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(y_batch.numpy().flatten())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # Metrics\n",
    "    test_mse = np.mean((all_targets - all_preds) ** 2)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    dir_acc = np.mean((np.sign(all_preds) == np.sign(all_targets)))\n",
    "    \n",
    "    lstm_results[set_name] = {\n",
    "        'n_features': len(feature_list),\n",
    "        'dir_acc': dir_acc,\n",
    "        'rmse': test_rmse,\n",
    "        'mse': test_mse,\n",
    "        'features': feature_list\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  Results: Dir Acc={dir_acc:.2%} | RMSE={test_rmse:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# COMPARISON TABLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LSTM FEATURE ABLATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Feature Set':<25} {'Features':>8} {'Dir Acc':>12} {'RMSE':>10} {'vs Baseline':>12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_acc = 0.5337  # MLP momentum_only\n",
    "\n",
    "sorted_results = sorted(lstm_results.items(), key=lambda x: x[1]['dir_acc'], reverse=True)\n",
    "\n",
    "for name, metrics in sorted_results:\n",
    "    improvement = (metrics['dir_acc'] - baseline_acc) * 100\n",
    "    marker = \" ⭐ BEST\" if name == sorted_results[0][0] else \"\"\n",
    "    \n",
    "    print(f\"{name:<25} {metrics['n_features']:>8} \"\n",
    "          f\"{metrics['dir_acc']:>12.2%} {metrics['rmse']:>10.4f} \"\n",
    "          f\"{improvement:+11.2f}pp{marker}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Redundancy Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REDUNDANCY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "momentum_orig = lstm_results['momentum_original']\n",
    "momentum_clean = lstm_results['momentum_clean']\n",
    "\n",
    "print(f\"momentum_original (5 feat, with RET_5/15): {momentum_orig['dir_acc']:.2%}\")\n",
    "print(f\"momentum_clean (3 feat, no redundancy):    {momentum_clean['dir_acc']:.2%}\")\n",
    "\n",
    "if momentum_clean['dir_acc'] >= momentum_orig['dir_acc']:\n",
    "    print(\"\\n✅ HYPOTHESIS CONFIRMED: RET_5 and RET_15 were redundant!\")\n",
    "    print(\"   → Removing them improved or maintained performance with fewer features\")\n",
    "else:\n",
    "    diff = (momentum_orig['dir_acc'] - momentum_clean['dir_acc']) * 100\n",
    "    print(f\"\\n⚠️  Redundant features helped by {diff:.2f}pp\")\n",
    "    print(\"   → They may encode something LSTM can't learn from RET_1 alone\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df658f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
